# Описание

Скрипт `deploy_llm.py` запускать на сервере с GPU. Убедитесь, что у вас как минимум 16 гигабайт видеопамяти.

Для того, чтобы подгрузить модель `meta-llama/Meta-Llama-3-8B-Instruct`, необходимо иметь аккаунт на https://huggingface.co/ и подать заявку на доступ к модели: https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct

После того, как вышеперечисленное сделано, запишите токен доступа с Huggingface (начинается с `hf_`) в переменную окружения `HUGGING_FACE_HUB_TOKEN` и запустите скрипт.

### TODO: написание Dockerfile для данного скрипта (приветствуются контрибьюторы)

